{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f6ec383",
   "metadata": {},
   "source": [
    "# ü§ñ **Generative AI Comprehensive Lecture Series**\n",
    "\n",
    "## **Applied Scientist Interview Preparation**\n",
    "### *Amazon & Tech Industry Focus*\n",
    "\n",
    "---\n",
    "\n",
    "## üìö **Course Overview**\n",
    "\n",
    "This comprehensive lecture series covers the fundamental and advanced concepts in Generative AI that every Applied Scientist should master. Designed specifically for Amazon Applied Scientist interviews and senior technical roles.\n",
    "\n",
    "### **üéØ Learning Objectives**\n",
    "By the end of this series, you will:\n",
    "1. **Master foundational concepts** in generative modeling\n",
    "2. **Understand modern architectures** (VAEs, GANs, Diffusion Models, LLMs)\n",
    "3. **Implement key algorithms** from scratch\n",
    "4. **Apply GenAI to real-world problems** and business scenarios\n",
    "5. **Navigate ethical considerations** and safety in AI\n",
    "6. **Demonstrate production deployment** knowledge\n",
    "\n",
    "### **üìñ Lecture Structure**\n",
    "- **4 Comprehensive Lectures** (90 minutes each)\n",
    "- **Hands-on Implementation** with working code\n",
    "- **Interview-focused assessments** and Q&A\n",
    "- **Real-world case studies** and applications\n",
    "- **Production considerations** and scalability\n",
    "\n",
    "### **üè¢ Target Audience**\n",
    "- Applied Scientists preparing for Amazon/Meta/Google interviews\n",
    "- ML Engineers transitioning to GenAI roles\n",
    "- Senior practitioners seeking comprehensive GenAI knowledge\n",
    "- Technical leaders building GenAI strategy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b831f8",
   "metadata": {},
   "source": [
    "# üìã **Prerequisites & Setup**\n",
    "\n",
    "## **Mathematical Background**\n",
    "- **Probability & Statistics**: Distributions, Bayes' theorem, KL divergence\n",
    "- **Linear Algebra**: Matrix operations, eigenvalues, SVD\n",
    "- **Calculus**: Gradients, chain rule, optimization\n",
    "- **Information Theory**: Entropy, mutual information\n",
    "\n",
    "## **Technical Prerequisites**\n",
    "- **Deep Learning**: Neural networks, backpropagation, optimization\n",
    "- **PyTorch/TensorFlow**: Tensor operations, autograd, model building\n",
    "- **Transformers**: Attention mechanisms, encoder-decoder architectures\n",
    "- **Computer Vision**: CNNs, image processing fundamentals\n",
    "\n",
    "## **Business Context**\n",
    "- Understanding of **product development** lifecycle\n",
    "- **Customer-centric thinking** and user experience design\n",
    "- **Scalability considerations** for production systems\n",
    "- **Ethical AI** and responsible deployment practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5426d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for GenAI implementations\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "import random\n",
    "from typing import Tuple, List, Dict, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c80de2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì **LECTURE 1: Foundations of Generative Modeling**\n",
    "## *Duration: 90 minutes*\n",
    "\n",
    "### **üìö Learning Objectives**\n",
    "- Understand the mathematical foundations of generative modeling\n",
    "- Distinguish between discriminative and generative models\n",
    "- Master probability distributions and density estimation\n",
    "- Implement basic generative models from scratch\n",
    "- Apply concepts to real-world scenarios\n",
    "\n",
    "---\n",
    "\n",
    "## **üßÆ 1.1 Mathematical Foundations**\n",
    "\n",
    "### **Generative vs Discriminative Models**\n",
    "\n",
    "**Discriminative Models**: Learn P(y|x)\n",
    "- Goal: Classify or predict given input\n",
    "- Examples: Logistic Regression, SVMs, Random Forests\n",
    "- Focus: Decision boundaries\n",
    "\n",
    "**Generative Models**: Learn P(x) or P(x,y)\n",
    "- Goal: Generate new samples from learned distribution\n",
    "- Examples: VAEs, GANs, Diffusion Models, LLMs\n",
    "- Focus: Data distribution modeling\n",
    "\n",
    "### **Key Mathematical Concepts**\n",
    "\n",
    "#### **1. Probability Density Functions**\n",
    "For continuous variables:\n",
    "```\n",
    "P(a ‚â§ X ‚â§ b) = ‚à´[a to b] p(x) dx\n",
    "```\n",
    "\n",
    "#### **2. Maximum Likelihood Estimation (MLE)**\n",
    "Given dataset D = {x‚ÇÅ, x‚ÇÇ, ..., x‚Çô}, find Œ∏ that maximizes:\n",
    "```\n",
    "L(Œ∏) = ‚àè·µ¢ p(x·µ¢|Œ∏)\n",
    "log L(Œ∏) = Œ£·µ¢ log p(x·µ¢|Œ∏)\n",
    "```\n",
    "\n",
    "#### **3. KL Divergence**\n",
    "Measures difference between distributions:\n",
    "```\n",
    "D_KL(P||Q) = ‚à´ p(x) log(p(x)/q(x)) dx\n",
    "```\n",
    "\n",
    "#### **4. Evidence Lower Bound (ELBO)**\n",
    "Key concept for VAEs:\n",
    "```\n",
    "log p(x) ‚â• E_q[log p(x|z)] - D_KL(q(z|x)||p(z))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical Foundations Implementation\n",
    "\n",
    "class ProbabilityDistributions:\n",
    "    \"\"\"Implementation of key probability distributions for GenAI\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def gaussian_pdf(x, mu=0, sigma=1):\n",
    "        \"\"\"Gaussian probability density function\"\"\"\n",
    "        return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def kl_divergence_gaussian(mu1, sigma1, mu2, sigma2):\n",
    "        \"\"\"KL divergence between two Gaussian distributions\"\"\"\n",
    "        return np.log(sigma2 / sigma1) + (sigma1**2 + (mu1 - mu2)**2) / (2 * sigma2**2) - 0.5\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample_gaussian(mu, sigma, n_samples=1000):\n",
    "        \"\"\"Sample from Gaussian distribution\"\"\"\n",
    "        return np.random.normal(mu, sigma, n_samples)\n",
    "\n",
    "# Demonstrate probability concepts\n",
    "prob_dist = ProbabilityDistributions()\n",
    "\n",
    "# Create sample data\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "y1 = prob_dist.gaussian_pdf(x, mu=0, sigma=1)\n",
    "y2 = prob_dist.gaussian_pdf(x, mu=1, sigma=1.5)\n",
    "\n",
    "# Plot distributions\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, y1, label='Œº=0, œÉ=1', linewidth=2)\n",
    "plt.plot(x, y2, label='Œº=1, œÉ=1.5', linewidth=2)\n",
    "plt.title('Gaussian Probability Density Functions')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and display KL divergence\n",
    "kl_div = prob_dist.kl_divergence_gaussian(0, 1, 1, 1.5)\n",
    "print(f\"KL Divergence D_KL(N(0,1)||N(1,1.5¬≤)): {kl_div:.4f}\")\n",
    "\n",
    "# Sample and plot histograms\n",
    "plt.subplot(1, 2, 2)\n",
    "samples1 = prob_dist.sample_gaussian(0, 1, 1000)\n",
    "samples2 = prob_dist.sample_gaussian(1, 1.5, 1000)\n",
    "\n",
    "plt.hist(samples1, bins=50, alpha=0.7, label='Œº=0, œÉ=1', density=True)\n",
    "plt.hist(samples2, bins=50, alpha=0.7, label='Œº=1, œÉ=1.5', density=True)\n",
    "plt.title('Sampled Data Histograms')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ **Key Insights:**\")\n",
    "print(\"1. Generative models learn the underlying data distribution p(x)\")\n",
    "print(\"2. KL divergence measures how different two distributions are\")\n",
    "print(\"3. Lower KL divergence = better approximation of target distribution\")\n",
    "print(\"4. MLE finds parameters that maximize likelihood of observed data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4fce6",
   "metadata": {},
   "source": [
    "## **üé≤ 1.2 Types of Generative Models**\n",
    "\n",
    "### **Taxonomy of Generative Models**\n",
    "\n",
    "```\n",
    "Generative Models\n",
    "‚îú‚îÄ‚îÄ Explicit Density Models\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Tractable Models\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Autoregressive Models (GPT, PixelCNN)\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Flow-based Models (RealNVP, Glow)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Approximate Density Models\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ Variational Autoencoders (VAEs)\n",
    "‚îî‚îÄ‚îÄ Implicit Density Models\n",
    "    ‚îú‚îÄ‚îÄ Generative Adversarial Networks (GANs)\n",
    "    ‚îî‚îÄ‚îÄ Diffusion Models (DDPM, DDIM)\n",
    "```\n",
    "\n",
    "### **Model Comparison**\n",
    "\n",
    "| Model Type | Pros | Cons | Best Use Cases |\n",
    "|------------|------|------|----------------|\n",
    "| **VAEs** | Stable training, good representations | Blurry outputs | Representation learning, data compression |\n",
    "| **GANs** | Sharp, realistic outputs | Training instability | Image generation, style transfer |\n",
    "| **Diffusion** | High quality, stable | Slow sampling | Image generation, inpainting |\n",
    "| **Autoregressive** | Exact likelihood, stable | Sequential generation | Text, code generation |\n",
    "| **Flows** | Exact likelihood, invertible | Limited expressiveness | Density estimation, anomaly detection |\n",
    "\n",
    "### **üéØ Interview Focus Points**\n",
    "1. **Trade-offs**: Quality vs Speed vs Stability\n",
    "2. **Use Cases**: When to choose each model type\n",
    "3. **Scalability**: Production deployment considerations\n",
    "4. **Evaluation**: How to measure generation quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Generative Model Implementation\n",
    "\n",
    "class SimpleGaussianGenerator(nn.Module):\n",
    "    \"\"\"A simple generative model that learns to generate 2D points from a Gaussian mixture\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=2, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Generator network\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)  # Output 2D points\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"Generate 2D points from latent code z\"\"\"\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def sample(self, n_samples=1000):\n",
    "        \"\"\"Sample n_samples points from the learned distribution\"\"\"\n",
    "        z = torch.randn(n_samples, self.latent_dim).to(device)\n",
    "        with torch.no_grad():\n",
    "            return self.forward(z)\n",
    "\n",
    "# Create target distribution (mixture of Gaussians)\n",
    "def create_target_data(n_samples=2000):\n",
    "    \"\"\"Create a mixture of Gaussians as target distribution\"\"\"\n",
    "    # Component 1: centered at (-2, -2)\n",
    "    x1 = np.random.multivariate_normal([-2, -2], [[0.5, 0], [0, 0.5]], n_samples//4)\n",
    "    \n",
    "    # Component 2: centered at (2, -2)\n",
    "    x2 = np.random.multivariate_normal([2, -2], [[0.5, 0], [0, 0.5]], n_samples//4)\n",
    "    \n",
    "    # Component 3: centered at (-2, 2)\n",
    "    x3 = np.random.multivariate_normal([-2, 2], [[0.5, 0], [0, 0.5]], n_samples//4)\n",
    "    \n",
    "    # Component 4: centered at (2, 2)\n",
    "    x4 = np.random.multivariate_normal([2, 2], [[0.5, 0], [0, 0.5]], n_samples//4)\n",
    "    \n",
    "    return np.vstack([x1, x2, x3, x4])\n",
    "\n",
    "# Train the simple generator\n",
    "def train_simple_generator(model, target_data, epochs=1000, lr=0.001):\n",
    "    \"\"\"Train the generator using Maximum Mean Discrepancy (MMD) loss\"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    target_tensor = torch.FloatTensor(target_data).to(device)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Sample from generator\n",
    "        z = torch.randn(len(target_data), model.latent_dim).to(device)\n",
    "        generated = model(z)\n",
    "        \n",
    "        # Simple MSE loss between distributions (simplified MMD)\n",
    "        target_mean = target_tensor.mean(dim=0)\n",
    "        generated_mean = generated.mean(dim=0)\n",
    "        \n",
    "        target_var = target_tensor.var(dim=0)\n",
    "        generated_var = generated.var(dim=0)\n",
    "        \n",
    "        loss = F.mse_loss(generated_mean, target_mean) + F.mse_loss(generated_var, target_var)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if epoch % 200 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Create and train the model\n",
    "target_data = create_target_data(2000)\n",
    "model = SimpleGaussianGenerator().to(device)\n",
    "\n",
    "print(\"Training simple generative model...\")\n",
    "losses = train_simple_generator(model, target_data, epochs=1000)\n",
    "\n",
    "# Generate samples and visualize\n",
    "generated_samples = model.sample(2000).cpu().numpy()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Target distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(target_data[:, 0], target_data[:, 1], alpha=0.6, s=20)\n",
    "plt.title('Target Distribution\\n(Mixture of 4 Gaussians)')\n",
    "plt.xlabel('X‚ÇÅ')\n",
    "plt.ylabel('X‚ÇÇ')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "\n",
    "# Generated distribution\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(generated_samples[:, 0], generated_samples[:, 1], alpha=0.6, s=20, color='orange')\n",
    "plt.title('Generated Distribution\\n(After Training)')\n",
    "plt.xlabel('X‚ÇÅ')\n",
    "plt.ylabel('X‚ÇÇ')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "\n",
    "# Training loss\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ **Key Observations:**\")\n",
    "print(\"1. Generator learns to approximate target distribution\")\n",
    "print(\"2. Quality depends on architecture and loss function\")\n",
    "print(\"3. Trade-off between model complexity and training stability\")\n",
    "print(\"4. Evaluation requires comparing distributions, not individual samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d8122",
   "metadata": {},
   "source": [
    "## **üß† 1.3 Autoregressive Models**\n",
    "\n",
    "### **Concept and Mathematical Foundation**\n",
    "\n",
    "Autoregressive models factorize the joint probability using the chain rule:\n",
    "\n",
    "```\n",
    "p(x‚ÇÅ, x‚ÇÇ, ..., x‚Çô) = ‚àè·µ¢‚Çå‚ÇÅ‚Åø p(x·µ¢ | x‚ÇÅ, x‚ÇÇ, ..., x·µ¢‚Çã‚ÇÅ)\n",
    "```\n",
    "\n",
    "### **Key Properties**\n",
    "- **Exact likelihood computation**: Can compute p(x) exactly\n",
    "- **Sequential generation**: Generate one element at a time\n",
    "- **Flexible**: Can model any distribution\n",
    "- **Stable training**: No adversarial training needed\n",
    "\n",
    "### **Applications**\n",
    "- **Language Models**: GPT, BERT (masked), Transformer-XL\n",
    "- **Image Models**: PixelCNN, PixelRNN\n",
    "- **Audio Models**: WaveNet, SampleRNN\n",
    "- **Code Generation**: Codex, CodeT5\n",
    "\n",
    "### **üéØ Interview Questions**\n",
    "1. \"How do autoregressive models handle variable-length sequences?\"\n",
    "2. \"What are the trade-offs between parallel training and sequential inference?\"\n",
    "3. \"How would you implement teacher forcing vs. free running?\"\n",
    "4. \"What are the challenges in autoregressive image generation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Autoregressive Model Implementation\n",
    "\n",
    "class SimpleAutoregressiveModel(nn.Module):\n",
    "    \"\"\"A simple autoregressive model for sequence generation\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=128, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # LSTM for sequential modeling\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        # For sampling\n",
    "        self.register_buffer('sos_token', torch.tensor(0))  # Start of sequence\n",
    "        self.register_buffer('eos_token', torch.tensor(1))  # End of sequence\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        \"\"\"Forward pass for training\"\"\"\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "        # Embed tokens\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        \n",
    "        # LSTM forward\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        # Project to vocabulary\n",
    "        logits = self.output_proj(lstm_out)  # (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        return logits, hidden\n",
    "    \n",
    "    def generate(self, max_length=20, temperature=1.0, top_k=None):\n",
    "        \"\"\"Generate sequences autoregressively\"\"\"\n",
    "        self.eval()\n",
    "        generated = [self.sos_token.item()]\n",
    "        hidden = None\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                # Current input\n",
    "                current_input = torch.tensor([[generated[-1]]]).to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                logits, hidden = self.forward(current_input, hidden)\n",
    "                \n",
    "                # Apply temperature\n",
    "                logits = logits[0, -1] / temperature\n",
    "                \n",
    "                # Apply top-k filtering\n",
    "                if top_k is not None:\n",
    "                    values, indices = torch.topk(logits, top_k)\n",
    "                    logits[logits < values[-1]] = -float('inf')\n",
    "                \n",
    "                # Sample next token\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                next_token = torch.multinomial(probs, 1).item()\n",
    "                \n",
    "                generated.append(next_token)\n",
    "                \n",
    "                # Stop at end of sequence\n",
    "                if next_token == self.eos_token.item():\n",
    "                    break\n",
    "        \n",
    "        return generated\n",
    "    \n",
    "    def compute_perplexity(self, data_loader):\n",
    "        \"\"\"Compute perplexity on dataset\"\"\"\n",
    "        self.eval()\n",
    "        total_loss = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in data_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                logits, _ = self.forward(inputs)\n",
    "                \n",
    "                # Compute cross-entropy loss\n",
    "                loss = F.cross_entropy(\n",
    "                    logits.view(-1, self.vocab_size),\n",
    "                    targets.view(-1),\n",
    "                    reduction='sum'\n",
    "                )\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_tokens += targets.numel()\n",
    "        \n",
    "        avg_loss = total_loss / total_tokens\n",
    "        perplexity = torch.exp(torch.tensor(avg_loss))\n",
    "        \n",
    "        return perplexity.item()\n",
    "\n",
    "# Create synthetic sequence data\n",
    "def create_sequence_data(vocab_size=10, seq_length=15, num_sequences=1000):\n",
    "    \"\"\"Create synthetic arithmetic sequences for demonstration\"\"\"\n",
    "    sequences = []\n",
    "    \n",
    "    for _ in range(num_sequences):\n",
    "        # Create arithmetic sequence: start, start+step, start+2*step, ...\n",
    "        start = np.random.randint(2, vocab_size-3)  # Leave room for SOS, EOS\n",
    "        step = np.random.choice([-1, 1])  # Up or down\n",
    "        \n",
    "        sequence = [0]  # SOS token\n",
    "        current = start\n",
    "        \n",
    "        for _ in range(seq_length-2):  # -2 for SOS and EOS\n",
    "            if 2 <= current < vocab_size-1:  # Valid range\n",
    "                sequence.append(current)\n",
    "                current += step\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        sequence.append(1)  # EOS token\n",
    "        \n",
    "        # Pad to fixed length\n",
    "        while len(sequence) < seq_length:\n",
    "            sequence.append(1)  # Pad with EOS\n",
    "        \n",
    "        sequences.append(sequence[:seq_length])\n",
    "    \n",
    "    return np.array(sequences)\n",
    "\n",
    "# Prepare data\n",
    "vocab_size = 10\n",
    "seq_length = 10\n",
    "sequences = create_sequence_data(vocab_size, seq_length, 1000)\n",
    "\n",
    "# Create input-target pairs (shift by one for autoregressive training)\n",
    "inputs = sequences[:, :-1]\n",
    "targets = sequences[:, 1:]\n",
    "\n",
    "# Convert to tensors and create data loader\n",
    "inputs_tensor = torch.LongTensor(inputs)\n",
    "targets_tensor = torch.LongTensor(targets)\n",
    "dataset = torch.utils.data.TensorDataset(inputs_tensor, targets_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create and train model\n",
    "model = SimpleAutoregressiveModel(vocab_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Training autoregressive model...\")\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_inputs, batch_targets in data_loader:\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, _ = model(batch_inputs)\n",
    "        loss = criterion(logits.view(-1, vocab_size), batch_targets.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(data_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Generate some sequences\n",
    "print(\"\\nüìù **Generated Sequences:**\")\n",
    "for i in range(5):\n",
    "    generated = model.generate(max_length=15, temperature=0.8)\n",
    "    print(f\"Sample {i+1}: {generated}\")\n",
    "\n",
    "# Compute perplexity\n",
    "perplexity = model.compute_perplexity(data_loader)\n",
    "print(f\"\\nüìä **Model Perplexity**: {perplexity:.2f}\")\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses)\n",
    "plt.title('Autoregressive Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ **Key Insights:**\")\n",
    "print(\"1. Autoregressive models predict next token given previous context\")\n",
    "print(\"2. Teacher forcing during training vs. free running during inference\")\n",
    "print(\"3. Temperature controls randomness in generation\")\n",
    "print(\"4. Perplexity measures how well model predicts the test data\")\n",
    "print(\"5. Lower perplexity = better language model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d269e6a",
   "metadata": {},
   "source": [
    "## **üîç 1.4 Evaluation Metrics for Generative Models**\n",
    "\n",
    "### **Quality Metrics**\n",
    "\n",
    "#### **1. Likelihood-based Metrics**\n",
    "- **Log-likelihood**: Higher is better\n",
    "- **Perplexity**: Lower is better (exp of negative log-likelihood)\n",
    "- **Bits per dimension**: Information-theoretic measure\n",
    "\n",
    "#### **2. Similarity Metrics**\n",
    "- **Inception Score (IS)**: Measures quality and diversity\n",
    "- **Fr√©chet Inception Distance (FID)**: Compares feature distributions\n",
    "- **LPIPS**: Learned perceptual similarity\n",
    "\n",
    "#### **3. Human Evaluation**\n",
    "- **Quality ratings**: Human judges rate realism\n",
    "- **Preference studies**: A/B testing between models\n",
    "- **Task-specific metrics**: BLEU for text, user engagement for recommendations\n",
    "\n",
    "### **Diversity Metrics**\n",
    "- **Mode coverage**: How many modes of data distribution are captured\n",
    "- **Precision and Recall**: Trade-off between quality and diversity\n",
    "- **Self-BLEU**: Diversity in text generation\n",
    "\n",
    "### **üéØ Business Metrics**\n",
    "- **User engagement**: Click-through rates, time spent\n",
    "- **Conversion rates**: Purchases, sign-ups\n",
    "- **A/B test results**: Statistical significance of improvements\n",
    "- **Computational cost**: Inference time, resource usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics Implementation\n",
    "\n",
    "class GenerativeModelEvaluator:\n",
    "    \"\"\"Comprehensive evaluation suite for generative models\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def inception_score(self, generated_images, batch_size=32, splits=10):\n",
    "        \"\"\"Simplified Inception Score calculation\"\"\"\n",
    "        # Note: This is a simplified version for demonstration\n",
    "        # Real implementation would use pre-trained Inception model\n",
    "        \n",
    "        # Simulate classifier predictions\n",
    "        n_samples = len(generated_images)\n",
    "        n_classes = 10\n",
    "        \n",
    "        # Random predictions for demonstration\n",
    "        predictions = np.random.dirichlet(np.ones(n_classes), n_samples)\n",
    "        \n",
    "        # Calculate IS\n",
    "        scores = []\n",
    "        for i in range(splits):\n",
    "            part = predictions[i * (n_samples // splits): (i + 1) * (n_samples // splits)]\n",
    "            p_y = np.mean(part, axis=0)\n",
    "            kl_divs = [np.sum(p * (np.log(p + 1e-10) - np.log(p_y + 1e-10))) for p in part]\n",
    "            scores.append(np.exp(np.mean(kl_divs)))\n",
    "        \n",
    "        return np.mean(scores), np.std(scores)\n",
    "    \n",
    "    def frechet_distance(self, real_features, generated_features):\n",
    "        \"\"\"Calculate Fr√©chet distance between real and generated features\"\"\"\n",
    "        # Calculate means\n",
    "        mu1, mu2 = np.mean(real_features, axis=0), np.mean(generated_features, axis=0)\n",
    "        \n",
    "        # Calculate covariances\n",
    "        sigma1 = np.cov(real_features, rowvar=False)\n",
    "        sigma2 = np.cov(generated_features, rowvar=False)\n",
    "        \n",
    "        # Calculate FID\n",
    "        diff = mu1 - mu2\n",
    "        fid = np.dot(diff, diff) + np.trace(sigma1 + sigma2 - 2 * np.sqrt(sigma1 @ sigma2))\n",
    "        \n",
    "        return fid\n",
    "    \n",
    "    def precision_recall(self, real_samples, generated_samples, k=3):\n",
    "        \"\"\"Calculate precision and recall for generative models\"\"\"\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        \n",
    "        # Fit k-NN on real samples\n",
    "        nbrs_real = NearestNeighbors(n_neighbors=k).fit(real_samples)\n",
    "        nbrs_gen = NearestNeighbors(n_neighbors=k).fit(generated_samples)\n",
    "        \n",
    "        # Calculate precision: fraction of generated samples close to real samples\n",
    "        distances_gen, _ = nbrs_real.kneighbors(generated_samples)\n",
    "        precision = np.mean(distances_gen[:, 0] < np.percentile(distances_gen[:, 0], 95))\n",
    "        \n",
    "        # Calculate recall: fraction of real samples close to generated samples\n",
    "        distances_real, _ = nbrs_gen.kneighbors(real_samples)\n",
    "        recall = np.mean(distances_real[:, 0] < np.percentile(distances_real[:, 0], 95))\n",
    "        \n",
    "        return precision, recall\n",
    "    \n",
    "    def mode_coverage(self, real_samples, generated_samples, threshold=0.5):\n",
    "        \"\"\"Estimate mode coverage using clustering\"\"\"\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn.metrics import pairwise_distances\n",
    "        \n",
    "        # Cluster real samples to identify modes\n",
    "        n_modes = min(10, len(real_samples) // 50)  # Heuristic for number of modes\n",
    "        kmeans = KMeans(n_clusters=n_modes, random_state=42)\n",
    "        real_clusters = kmeans.fit_predict(real_samples)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # For each mode, check if generated samples are close\n",
    "        covered_modes = 0\n",
    "        for center in centers:\n",
    "            distances = pairwise_distances([center], generated_samples)[0]\n",
    "            if np.min(distances) < threshold:\n",
    "                covered_modes += 1\n",
    "        \n",
    "        coverage = covered_modes / n_modes\n",
    "        return coverage, n_modes\n",
    "    \n",
    "    def compute_all_metrics(self, real_samples, generated_samples):\n",
    "        \"\"\"Compute comprehensive evaluation metrics\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Inception Score\n",
    "        is_mean, is_std = self.inception_score(generated_samples)\n",
    "        results['inception_score'] = {'mean': is_mean, 'std': is_std}\n",
    "        \n",
    "        # Fr√©chet Distance (simplified with raw samples as features)\n",
    "        fid = self.frechet_distance(real_samples, generated_samples)\n",
    "        results['frechet_distance'] = fid\n",
    "        \n",
    "        # Precision and Recall\n",
    "        precision, recall = self.precision_recall(real_samples, generated_samples)\n",
    "        results['precision'] = precision\n",
    "        results['recall'] = recall\n",
    "        results['f1_score'] = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "        \n",
    "        # Mode Coverage\n",
    "        coverage, n_modes = self.mode_coverage(real_samples, generated_samples)\n",
    "        results['mode_coverage'] = {'coverage': coverage, 'total_modes': n_modes}\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Demonstrate evaluation on our previous simple generator\n",
    "evaluator = GenerativeModelEvaluator()\n",
    "\n",
    "# Use our previous target and generated data\n",
    "real_data = target_data\n",
    "generated_data = generated_samples\n",
    "\n",
    "print(\"üîç **Evaluating Generative Model Performance**\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compute all metrics\n",
    "metrics = evaluator.compute_all_metrics(real_data, generated_data)\n",
    "\n",
    "print(f\"üìä **Inception Score**: {metrics['inception_score']['mean']:.3f} ¬± {metrics['inception_score']['std']:.3f}\")\n",
    "print(f\"üìè **Fr√©chet Distance**: {metrics['frechet_distance']:.3f}\")\n",
    "print(f\"üéØ **Precision**: {metrics['precision']:.3f}\")\n",
    "print(f\"üîÑ **Recall**: {metrics['recall']:.3f}\")\n",
    "print(f\"‚öñÔ∏è **F1 Score**: {metrics['f1_score']:.3f}\")\n",
    "print(f\"üé≠ **Mode Coverage**: {metrics['mode_coverage']['coverage']:.3f} ({metrics['mode_coverage']['total_modes']} modes)\")\n",
    "\n",
    "# Visualize precision-recall trade-off\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot original and generated distributions\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(real_data[:, 0], real_data[:, 1], alpha=0.6, label='Real', s=20)\n",
    "plt.scatter(generated_data[:, 0], generated_data[:, 1], alpha=0.6, label='Generated', s=20)\n",
    "plt.title('Real vs Generated Distributions')\n",
    "plt.xlabel('X‚ÇÅ')\n",
    "plt.ylabel('X‚ÇÇ')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "\n",
    "# Plot metrics comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "metric_names = ['Precision', 'Recall', 'F1 Score', 'Mode Coverage']\n",
    "metric_values = [metrics['precision'], metrics['recall'], \n",
    "                metrics['f1_score'], metrics['mode_coverage']['coverage']]\n",
    "\n",
    "bars = plt.bar(metric_names, metric_values, alpha=0.7)\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, metric_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ **Evaluation Best Practices:**\")\n",
    "print(\"1. **Multiple Metrics**: No single metric captures all aspects\")\n",
    "print(\"2. **Quality vs Diversity**: Precision-Recall trade-off\")\n",
    "print(\"3. **Domain-Specific**: Choose metrics relevant to your application\")\n",
    "print(\"4. **Human Evaluation**: Ultimate test for many applications\")\n",
    "print(\"5. **Business Metrics**: Align with actual product success\")\n",
    "\n",
    "print(\"\\nüìà **Interpretation:**\")\n",
    "print(f\"‚Ä¢ High Precision ({metrics['precision']:.3f}): Generated samples are realistic\")\n",
    "print(f\"‚Ä¢ High Recall ({metrics['recall']:.3f}): Covers the real data distribution well\")\n",
    "print(f\"‚Ä¢ Mode Coverage ({metrics['mode_coverage']['coverage']:.3f}): Captures most data modes\")\n",
    "print(f\"‚Ä¢ Low FID ({metrics['frechet_distance']:.3f}): Similar feature distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd5e6cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéì **LECTURE 2: Variational Autoencoders (VAEs)**\n",
    "## *Duration: 90 minutes*\n",
    "\n",
    "### **üìö Learning Objectives**\n",
    "- Master the mathematical foundations of VAEs and ELBO\n",
    "- Understand the reparameterization trick and its importance\n",
    "- Implement VAEs from scratch with proper training procedures\n",
    "- Explore advanced VAE variants (Œ≤-VAE, WAE, VQ-VAE)\n",
    "- Apply VAEs to real-world representation learning problems\n",
    "\n",
    "---\n",
    "\n",
    "## **üßÆ 2.1 Mathematical Foundation of VAEs**\n",
    "\n",
    "### **The Generative Model Setup**\n",
    "\n",
    "VAEs model data using a latent variable model:\n",
    "- **Latent variables**: z ~ p(z) (typically N(0,I))\n",
    "- **Generative model**: p_Œ∏(x|z) (decoder)\n",
    "- **Inference model**: q_œÜ(z|x) (encoder)\n",
    "\n",
    "### **The Variational Lower Bound (ELBO)**\n",
    "\n",
    "The key insight: We want to maximize log p(x), but it's intractable.\n",
    "\n",
    "```\n",
    "log p(x) = log ‚à´ p(x,z) dz = log ‚à´ p(x|z)p(z) dz\n",
    "```\n",
    "\n",
    "Using Jensen's inequality with variational distribution q(z|x):\n",
    "\n",
    "```\n",
    "log p(x) ‚â• E_q(z|x)[log p(x|z)] - D_KL(q(z|x)||p(z))\n",
    "```\n",
    "\n",
    "This is the **Evidence Lower BOund (ELBO)**:\n",
    "\n",
    "```\n",
    "L(Œ∏,œÜ;x) = E_q_œÜ(z|x)[log p_Œ∏(x|z)] - D_KL(q_œÜ(z|x)||p(z))\n",
    "           ‚Üë                           ‚Üë\n",
    "    Reconstruction Loss         Regularization Loss\n",
    "```\n",
    "\n",
    "### **The Reparameterization Trick**\n",
    "\n",
    "Problem: Cannot backpropagate through random sampling.\n",
    "\n",
    "Solution: Reparameterize z = Œº + œÉ ‚äô Œµ, where Œµ ~ N(0,I)\n",
    "\n",
    "```\n",
    "z ~ q_œÜ(z|x) = N(Œº_œÜ(x), œÉ_œÜ¬≤(x))\n",
    "z = Œº_œÜ(x) + œÉ_œÜ(x) ‚äô Œµ, where Œµ ~ N(0,I)\n",
    "```\n",
    "\n",
    "### **üéØ Key Advantages of VAEs**\n",
    "1. **Stable Training**: No adversarial optimization\n",
    "2. **Principled**: Derived from maximum likelihood\n",
    "3. **Latent Representation**: Meaningful continuous latent space\n",
    "4. **Tractable**: Can compute exact ELBO\n",
    "\n",
    "### **üéØ Key Limitations**\n",
    "1. **Blurry Outputs**: Due to reconstruction loss (MSE/BCE)\n",
    "2. **Posterior Collapse**: All latents become the same\n",
    "3. **Limited Expressiveness**: Gaussian assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive VAE Implementation\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"Variational Autoencoder with proper ELBO optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder network (inference model q_œÜ(z|x))\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Latent space parameters\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder network (generative model p_Œ∏(x|z))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # For MNIST (pixel values in [0,1])\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent distribution parameters\"\"\"\n",
    "        h = self.encoder(x)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization trick: z = Œº + œÉ‚äôŒµ\"\"\"\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        else:\n",
    "            return mu  # Use mean for deterministic inference\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode latent variable to reconstruction\"\"\"\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Complete forward pass\"\"\"\n",
    "        # Flatten input if needed\n",
    "        if len(x.shape) > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Encode\n",
    "        mu, logvar = self.encode(x)\n",
    "        \n",
    "        # Reparameterize\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        # Decode\n",
    "        recon_x = self.decode(z)\n",
    "        \n",
    "        return recon_x, mu, logvar, z\n",
    "    \n",
    "    def sample(self, num_samples=64):\n",
    "        \"\"\"Generate samples from prior\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(num_samples, self.latent_dim).to(device)\n",
    "            samples = self.decode(z)\n",
    "        return samples\n",
    "    \n",
    "    def interpolate(self, x1, x2, num_steps=10):\n",
    "        \"\"\"Interpolate between two inputs in latent space\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Encode both inputs\n",
    "            mu1, _ = self.encode(x1.view(1, -1))\n",
    "            mu2, _ = self.encode(x2.view(1, -1))\n",
    "            \n",
    "            # Interpolate in latent space\n",
    "            interpolations = []\n",
    "            for i in range(num_steps):\n",
    "                alpha = i / (num_steps - 1)\n",
    "                z_interp = (1 - alpha) * mu1 + alpha * mu2\n",
    "                x_interp = self.decode(z_interp)\n",
    "                interpolations.append(x_interp)\n",
    "            \n",
    "            return torch.cat(interpolations, dim=0)\n",
    "\n",
    "def vae_loss_function(recon_x, x, mu, logvar, beta=1.0):\n",
    "    \"\"\"\n",
    "    VAE loss function (negative ELBO)\n",
    "    \n",
    "    Args:\n",
    "        recon_x: Reconstructed input\n",
    "        x: Original input\n",
    "        mu: Latent mean\n",
    "        logvar: Latent log variance\n",
    "        beta: Weight for KL divergence (Œ≤-VAE)\n",
    "    \n",
    "    Returns:\n",
    "        loss: Total loss\n",
    "        reconstruction_loss: Reconstruction term\n",
    "        kl_loss: KL divergence term\n",
    "    \"\"\"\n",
    "    # Flatten inputs\n",
    "    if len(x.shape) > 2:\n",
    "        x = x.view(x.size(0), -1)\n",
    "    if len(recon_x.shape) > 2:\n",
    "        recon_x = recon_x.view(recon_x.size(0), -1)\n",
    "    \n",
    "    # Reconstruction loss (negative log-likelihood)\n",
    "    # For MNIST, we use binary cross-entropy\n",
    "    reconstruction_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # KL divergence: D_KL(q(z|x) || p(z))\n",
    "    # Analytical form for Gaussian q and standard normal p\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Total loss\n",
    "    loss = reconstruction_loss + beta * kl_loss\n",
    "    \n",
    "    return loss, reconstruction_loss, kl_loss\n",
    "\n",
    "# Advanced VAE Training Class\n",
    "class VAETrainer:\n",
    "    \"\"\"Comprehensive VAE training with monitoring and evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device='cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.kl_losses = []\n",
    "        self.recon_losses = []\n",
    "        \n",
    "    def train_epoch(self, train_loader, optimizer, beta=1.0):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_recon_loss = 0\n",
    "        epoch_kl_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            recon_batch, mu, logvar, z = self.model(data)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss, recon_loss, kl_loss = vae_loss_function(\n",
    "                recon_batch, data, mu, logvar, beta\n",
    "            )\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_recon_loss += recon_loss.item()\n",
    "            epoch_kl_loss += kl_loss.item()\n",
    "        \n",
    "        # Average losses\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        epoch_recon_loss /= len(train_loader.dataset)\n",
    "        epoch_kl_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        return epoch_loss, epoch_recon_loss, epoch_kl_loss\n",
    "    \n",
    "    def validate(self, val_loader, beta=1.0):\n",
    "        \"\"\"Validate the model\"\"\"\n",
    "        self.model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, _ in val_loader:\n",
    "                data = data.to(self.device)\n",
    "                recon_batch, mu, logvar, z = self.model(data)\n",
    "                loss, _, _ = vae_loss_function(recon_batch, data, mu, logvar, beta)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        return val_loss\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=50, lr=1e-3, beta=1.0, \n",
    "              beta_schedule=None, print_every=10):\n",
    "        \"\"\"Complete training loop\"\"\"\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        print(f\"Training VAE for {epochs} epochs...\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Adjust beta if schedule provided\n",
    "            current_beta = beta\n",
    "            if beta_schedule:\n",
    "                current_beta = beta_schedule(epoch, epochs)\n",
    "            \n",
    "            # Train\n",
    "            train_loss, recon_loss, kl_loss = self.train_epoch(\n",
    "                train_loader, optimizer, current_beta\n",
    "            )\n",
    "            \n",
    "            # Validate\n",
    "            val_loss = self.validate(val_loader, current_beta)\n",
    "            \n",
    "            # Store losses\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.recon_losses.append(recon_loss)\n",
    "            self.kl_losses.append(kl_loss)\n",
    "            \n",
    "            # Print progress\n",
    "            if epoch % print_every == 0:\n",
    "                print(f'Epoch {epoch:3d}: Train Loss: {train_loss:.4f}, '\n",
    "                      f'Val Loss: {val_loss:.4f}, '\n",
    "                      f'Recon: {recon_loss:.4f}, '\n",
    "                      f'KL: {kl_loss:.4f}, '\n",
    "                      f'Œ≤: {current_beta:.3f}')\n",
    "    \n",
    "    def plot_training_curves(self):\n",
    "        \"\"\"Plot training curves\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Total loss\n",
    "        axes[0, 0].plot(self.train_losses, label='Train')\n",
    "        axes[0, 0].plot(self.val_losses, label='Validation')\n",
    "        axes[0, 0].set_title('Total Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        axes[0, 1].plot(self.recon_losses)\n",
    "        axes[0, 1].set_title('Reconstruction Loss')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Loss')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # KL loss\n",
    "        axes[1, 0].plot(self.kl_losses)\n",
    "        axes[1, 0].set_title('KL Divergence')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('KL Loss')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Loss ratio\n",
    "        recon_ratio = np.array(self.recon_losses) / (np.array(self.recon_losses) + np.array(self.kl_losses))\n",
    "        axes[1, 1].plot(recon_ratio)\n",
    "        axes[1, 1].set_title('Reconstruction Loss Ratio')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Recon / (Recon + KL)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Beta scheduling for Œ≤-VAE\n",
    "def beta_schedule_cyclical(epoch, total_epochs, n_cycles=4):\n",
    "    \"\"\"Cyclical beta schedule for better training\"\"\"\n",
    "    cycle_length = total_epochs // n_cycles\n",
    "    cycle_pos = epoch % cycle_length\n",
    "    return min(1.0, cycle_pos / (cycle_length * 0.5))\n",
    "\n",
    "def beta_schedule_linear(epoch, total_epochs, max_beta=1.0):\n",
    "    \"\"\"Linear beta schedule\"\"\"\n",
    "    return min(max_beta, epoch / (total_epochs * 0.5))\n",
    "\n",
    "# Load and prepare MNIST data\n",
    "def load_mnist_for_vae(batch_size=128):\n",
    "    \"\"\"Load MNIST data for VAE training\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Demonstration\n",
    "print(\"üèóÔ∏è **Setting up VAE training on MNIST**\")\n",
    "\n",
    "# Load data\n",
    "train_loader, test_loader = load_mnist_for_vae(batch_size=128)\n",
    "print(f\"‚úÖ Loaded MNIST: {len(train_loader.dataset)} train, {len(test_loader.dataset)} test samples\")\n",
    "\n",
    "# Create VAE model\n",
    "vae = VAE(input_dim=784, hidden_dim=400, latent_dim=20)\n",
    "print(f\"‚úÖ Created VAE with {sum(p.numel() for p in vae.parameters()):,} parameters\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = VAETrainer(vae, device)\n",
    "\n",
    "# Train the model\n",
    "print(\"üöÄ **Starting VAE training...**\")\n",
    "trainer.train(\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    epochs=30, \n",
    "    lr=1e-3, \n",
    "    beta=1.0,\n",
    "    print_every=5\n",
    ")\n",
    "\n",
    "print(\"‚úÖ **Training completed!**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdeae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Visualization and Analysis\n",
    "\n",
    "def visualize_vae_results(vae, test_loader, device, num_samples=10):\n",
    "    \"\"\"Comprehensive VAE visualization\"\"\"\n",
    "    vae.eval()\n",
    "    \n",
    "    # Get test batch\n",
    "    test_data, _ = next(iter(test_loader))\n",
    "    test_data = test_data.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Reconstructions\n",
    "        recon_data, mu, logvar, z = vae(test_data[:num_samples])\n",
    "        \n",
    "        # Generated samples\n",
    "        generated = vae.sample(num_samples)\n",
    "        \n",
    "        # Interpolations\n",
    "        interpolated = vae.interpolate(test_data[0], test_data[1], num_steps=num_samples)\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(4, num_samples, figsize=(num_samples*2, 8))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original\n",
    "        axes[0, i].imshow(test_data[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].set_title('Original' if i == 0 else '')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Reconstruction\n",
    "        axes[1, i].imshow(recon_data[i].cpu().view(28, 28), cmap='gray')\n",
    "        axes[1, i].set_title('Reconstruction' if i == 0 else '')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # Generated\n",
    "        axes[2, i].imshow(generated[i].cpu().view(28, 28), cmap='gray')\n",
    "        axes[2, i].set_title('Generated' if i == 0 else '')\n",
    "        axes[2, i].axis('off')\n",
    "        \n",
    "        # Interpolation\n",
    "        axes[3, i].imshow(interpolated[i].cpu().view(28, 28), cmap='gray')\n",
    "        axes[3, i].set_title('Interpolation' if i == 0 else '')\n",
    "        axes[3, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_latent_space(vae, test_loader, device, num_samples=1000):\n",
    "    \"\"\"Analyze the learned latent space\"\"\"\n",
    "    vae.eval()\n",
    "    \n",
    "    latents = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (data, label) in enumerate(test_loader):\n",
    "            if len(latents) * test_loader.batch_size >= num_samples:\n",
    "                break\n",
    "                \n",
    "            data = data.to(device)\n",
    "            mu, logvar = vae.encode(data)\n",
    "            latents.append(mu.cpu())\n",
    "            labels.append(label)\n",
    "    \n",
    "    latents = torch.cat(latents, dim=0)[:num_samples]\n",
    "    labels = torch.cat(labels, dim=0)[:num_samples]\n",
    "    \n",
    "    # Apply t-SNE for visualization if latent_dim > 2\n",
    "    if vae.latent_dim > 2:\n",
    "        print(\"Applying t-SNE for latent space visualization...\")\n",
    "        tsne = TSNE(n_components=2, random_state=42)\n",
    "        latents_2d = tsne.fit_transform(latents.numpy())\n",
    "    else:\n",
    "        latents_2d = latents.numpy()\n",
    "    \n",
    "    # Plot latent space\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Latent space colored by digit\n",
    "    plt.subplot(1, 2, 1)\n",
    "    scatter = plt.scatter(latents_2d[:, 0], latents_2d[:, 1], c=labels, cmap='tab10', alpha=0.7)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title('Latent Space (colored by digit)')\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    \n",
    "    # Latent space density\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist2d(latents_2d[:, 0], latents_2d[:, 1], bins=50, cmap='Blues')\n",
    "    plt.colorbar()\n",
    "    plt.title('Latent Space Density')\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return latents_2d, labels\n",
    "\n",
    "def evaluate_vae_metrics(vae, test_loader, device):\n",
    "    \"\"\"Evaluate VAE using various metrics\"\"\"\n",
    "    vae.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            recon_data, mu, logvar, z = vae(data)\n",
    "            \n",
    "            loss, recon_loss, kl_loss = vae_loss_function(recon_data, data, mu, logvar)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_kl_loss += kl_loss.item()\n",
    "            num_samples += data.size(0)\n",
    "    \n",
    "    # Average losses\n",
    "    avg_loss = total_loss / num_samples\n",
    "    avg_recon_loss = total_recon_loss / num_samples\n",
    "    avg_kl_loss = total_kl_loss / num_samples\n",
    "    \n",
    "    # Log-likelihood approximation\n",
    "    log_likelihood = -avg_loss\n",
    "    \n",
    "    # Bits per dimension\n",
    "    bits_per_dim = avg_loss / (np.log(2) * 784)  # 784 = 28*28 for MNIST\n",
    "    \n",
    "    print(\"üìä **VAE Evaluation Metrics:**\")\n",
    "    print(f\"Average Test Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Reconstruction Loss: {avg_recon_loss:.4f}\")\n",
    "    print(f\"KL Divergence: {avg_kl_loss:.4f}\")\n",
    "    print(f\"Log-Likelihood (approx): {log_likelihood:.4f}\")\n",
    "    print(f\"Bits per Dimension: {bits_per_dim:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'total_loss': avg_loss,\n",
    "        'reconstruction_loss': avg_recon_loss,\n",
    "        'kl_loss': avg_kl_loss,\n",
    "        'log_likelihood': log_likelihood,\n",
    "        'bits_per_dim': bits_per_dim\n",
    "    }\n",
    "\n",
    "# Run comprehensive evaluation\n",
    "print(\"üîç **Evaluating trained VAE...**\")\n",
    "\n",
    "# Plot training curves\n",
    "trainer.plot_training_curves()\n",
    "\n",
    "# Visualize results\n",
    "print(\"üé® **Visualizing VAE results...**\")\n",
    "visualize_vae_results(vae, test_loader, device, num_samples=8)\n",
    "\n",
    "# Analyze latent space\n",
    "print(\"üß† **Analyzing latent space...**\")\n",
    "latents_2d, labels = analyze_latent_space(vae, test_loader, device, num_samples=1000)\n",
    "\n",
    "# Evaluate metrics\n",
    "metrics = evaluate_vae_metrics(vae, test_loader, device)\n",
    "\n",
    "print(\"\\nüéØ **Key Insights:**\")\n",
    "print(\"1. **Reconstruction Quality**: How well VAE reconstructs inputs\")\n",
    "print(\"2. **Latent Structure**: Meaningful organization in latent space\")\n",
    "print(\"3. **Generation Quality**: Samples from prior distribution\")\n",
    "print(\"4. **Interpolation**: Smooth transitions in latent space\")\n",
    "print(\"5. **Bits per Dimension**: Compression efficiency metric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cbea5a",
   "metadata": {},
   "source": [
    "## **üöÄ 2.2 Advanced VAE Variants**\n",
    "\n",
    "### **Œ≤-VAE: Controlling Disentanglement**\n",
    "\n",
    "Œ≤-VAE modifies the ELBO by introducing a hyperparameter Œ≤:\n",
    "\n",
    "```\n",
    "L_Œ≤ = E_q(z|x)[log p(x|z)] - Œ≤¬∑D_KL(q(z|x)||p(z))\n",
    "```\n",
    "\n",
    "**Effects of Œ≤:**\n",
    "- **Œ≤ < 1**: Prioritizes reconstruction, may lead to posterior collapse\n",
    "- **Œ≤ = 1**: Standard VAE\n",
    "- **Œ≤ > 1**: Encourages disentanglement, may hurt reconstruction\n",
    "\n",
    "### **Wasserstein AutoEncoder (WAE)**\n",
    "\n",
    "WAE replaces KL divergence with Wasserstein distance:\n",
    "\n",
    "```\n",
    "L_WAE = E_q(z|x)[c(x, G(z))] + Œª¬∑W_c(q_Z, p_Z)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- c(x, G(z)) is the reconstruction cost\n",
    "- W_c is the Wasserstein distance\n",
    "- Œª controls the regularization strength\n",
    "\n",
    "### **Vector Quantized VAE (VQ-VAE)**\n",
    "\n",
    "VQ-VAE uses discrete latent representations:\n",
    "\n",
    "```\n",
    "z_q = e_k where k = argmin_j ||z_e - e_j||_2\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- **Discrete latents**: No posterior collapse\n",
    "- **Codebook learning**: Learnable discrete representations\n",
    "- **Straight-through estimator**: Gradient approximation\n",
    "\n",
    "### **üéØ Interview Focus: When to Use Each Variant**\n",
    "\n",
    "| Variant | Best For | Trade-offs |\n",
    "|---------|----------|------------|\n",
    "| **Standard VAE** | General representation learning | Blurry reconstructions |\n",
    "| **Œ≤-VAE** | Disentangled representations | Reconstruction vs disentanglement |\n",
    "| **WAE** | Better sample quality | More complex training |\n",
    "| **VQ-VAE** | Discrete representations, autoregressive modeling | Limited continuous interpolation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced VAE Variants Implementation\n",
    "\n",
    "class BetaVAE(VAE):\n",
    "    \"\"\"Œ≤-VAE for disentangled representation learning\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20, beta=4.0):\n",
    "        super().__init__(input_dim, hidden_dim, latent_dim)\n",
    "        self.beta = beta\n",
    "    \n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        \"\"\"Œ≤-VAE loss function\"\"\"\n",
    "        return vae_loss_function(recon_x, x, mu, logvar, beta=self.beta)\n",
    "\n",
    "class VectorQuantizer(nn.Module):\n",
    "    \"\"\"Vector Quantization layer for VQ-VAE\"\"\"\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost=0.25):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.commitment_cost = commitment_cost\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        self.embeddings = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.embeddings.weight.data.uniform_(-1/num_embeddings, 1/num_embeddings)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Quantize inputs using codebook\n",
    "        \n",
    "        Args:\n",
    "            inputs: (batch_size, embedding_dim, height, width)\n",
    "        Returns:\n",
    "            quantized: Quantized version of inputs\n",
    "            vq_loss: Vector quantization loss\n",
    "            encoding_indices: Indices of chosen embeddings\n",
    "        \"\"\"\n",
    "        # Convert inputs from BCHW -> BHWC\n",
    "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self.embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self.embeddings.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self.embeddings.weight.t()))\n",
    "        \n",
    "        # Find closest embeddings\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self.num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self.embeddings.weight).view(input_shape)\n",
    "        \n",
    "        # Calculate VQ loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        vq_loss = q_latent_loss + self.commitment_cost * e_latent_loss\n",
    "        \n",
    "        # Straight-through estimator\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        \n",
    "        # Convert back to BCHW\n",
    "        quantized = quantized.permute(0, 3, 1, 2).contiguous()\n",
    "        \n",
    "        return quantized, vq_loss, encoding_indices\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "    \"\"\"Vector Quantized VAE implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, num_embeddings=512, embedding_dim=64, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, hidden_dim, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_dim, embedding_dim, 1)\n",
    "        )\n",
    "        \n",
    "        # Vector Quantizer\n",
    "        self.vq = VectorQuantizer(num_embeddings, embedding_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(embedding_dim, hidden_dim, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(hidden_dim, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, 3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        z_e = self.encoder(x)\n",
    "        \n",
    "        # Quantize\n",
    "        z_q, vq_loss, encoding_indices = self.vq(z_e)\n",
    "        \n",
    "        # Decode\n",
    "        recon = self.decoder(z_q)\n",
    "        \n",
    "        return recon, vq_loss, encoding_indices\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to discrete indices\"\"\"\n",
    "        z_e = self.encoder(x)\n",
    "        _, _, encoding_indices = self.vq(z_e)\n",
    "        return encoding_indices\n",
    "    \n",
    "    def decode_indices(self, indices):\n",
    "        \"\"\"Decode from discrete indices\"\"\"\n",
    "        # Convert indices to quantized vectors\n",
    "        z_q = self.vq.embeddings(indices)\n",
    "        \n",
    "        # Reshape for decoder (assuming 7x7 spatial dimension for MNIST)\n",
    "        z_q = z_q.view(-1, self.embedding_dim, 7, 7)\n",
    "        \n",
    "        return self.decoder(z_q)\n",
    "\n",
    "def train_vqvae(model, train_loader, epochs=30, lr=1e-3):\n",
    "    \"\"\"Train VQ-VAE model\"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_recon_loss = 0\n",
    "        epoch_vq_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            recon, vq_loss, _ = model(data)\n",
    "            \n",
    "            # Reconstruction loss\n",
    "            recon_loss = F.binary_cross_entropy(recon, data, reduction='sum')\n",
    "            \n",
    "            # Total loss\n",
    "            loss = recon_loss + vq_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_recon_loss += recon_loss.item()\n",
    "            epoch_vq_loss += vq_loss.item()\n",
    "        \n",
    "        # Average losses\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        epoch_recon_loss /= len(train_loader.dataset)\n",
    "        epoch_vq_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch:3d}: Total: {epoch_loss:.4f}, '\n",
    "                  f'Recon: {epoch_recon_loss:.4f}, VQ: {epoch_vq_loss:.4f}')\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# Demonstration of advanced variants\n",
    "print(\"üöÄ **Training Advanced VAE Variants**\")\n",
    "\n",
    "# 1. Œ≤-VAE with different Œ≤ values\n",
    "print(\"\\n1Ô∏è‚É£ **Œ≤-VAE Training (Œ≤=4.0 for disentanglement)**\")\n",
    "beta_vae = BetaVAE(beta=4.0).to(device)\n",
    "beta_trainer = VAETrainer(beta_vae, device)\n",
    "beta_trainer.train(train_loader, test_loader, epochs=20, lr=1e-3, print_every=5)\n",
    "\n",
    "# 2. VQ-VAE\n",
    "print(\"\\n2Ô∏è‚É£ **VQ-VAE Training**\")\n",
    "vq_vae = VQVAE(num_embeddings=256, embedding_dim=64).to(device)\n",
    "vq_losses = train_vqvae(vq_vae, train_loader, epochs=20, lr=1e-3)\n",
    "\n",
    "# Compare models\n",
    "def compare_vae_variants(standard_vae, beta_vae, vq_vae, test_loader):\n",
    "    \"\"\"Compare different VAE variants\"\"\"\n",
    "    fig, axes = plt.subplots(3, 8, figsize=(16, 6))\n",
    "    \n",
    "    # Get test data\n",
    "    test_data, _ = next(iter(test_loader))\n",
    "    test_data = test_data[:8].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Standard VAE\n",
    "        recon_std, _, _, _ = standard_vae(test_data)\n",
    "        \n",
    "        # Œ≤-VAE\n",
    "        recon_beta, _, _, _ = beta_vae(test_data)\n",
    "        \n",
    "        # VQ-VAE\n",
    "        recon_vq, _, _ = vq_vae(test_data)\n",
    "    \n",
    "    for i in range(8):\n",
    "        # Standard VAE\n",
    "        axes[0, i].imshow(recon_std[i].cpu().view(28, 28), cmap='gray')\n",
    "        axes[0, i].set_title('Standard VAE' if i == 0 else '')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Œ≤-VAE\n",
    "        axes[1, i].imshow(recon_beta[i].cpu().view(28, 28), cmap='gray')\n",
    "        axes[1, i].set_title('Œ≤-VAE (Œ≤=4.0)' if i == 0 else '')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # VQ-VAE\n",
    "        axes[2, i].imshow(recon_vq[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[2, i].set_title('VQ-VAE' if i == 0 else '')\n",
    "        axes[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compare the models\n",
    "print(\"\\nüîÑ **Comparing VAE Variants**\")\n",
    "compare_vae_variants(vae, beta_vae, vq_vae, test_loader)\n",
    "\n",
    "# Plot training comparison\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(trainer.train_losses, label='Standard VAE')\n",
    "plt.title('Standard VAE Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(beta_trainer.train_losses, label='Œ≤-VAE', color='orange')\n",
    "plt.title('Œ≤-VAE Training (Œ≤=4.0)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(vq_losses, label='VQ-VAE', color='green')\n",
    "plt.title('VQ-VAE Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ **Key Comparisons:**\")\n",
    "print(\"1. **Standard VAE**: Balanced reconstruction and regularization\")\n",
    "print(\"2. **Œ≤-VAE**: Better disentanglement but potentially worse reconstruction\")\n",
    "print(\"3. **VQ-VAE**: Discrete representations, no posterior collapse\")\n",
    "print(\"4. **Training Stability**: VQ-VAE most stable, Œ≤-VAE depends on Œ≤ value\")\n",
    "print(\"5. **Use Cases**: Choose based on application requirements\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
